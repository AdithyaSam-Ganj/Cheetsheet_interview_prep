{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# siungle variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "# Assuming data is a pandas DataFrame with a single column\n",
    "data = pd.read_csv('your_time_series_data.csv')\n",
    "series = data['your_column_name'].values\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "series_scaled = scaler.fit_transform(series.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(series_scaled) * 0.8)\n",
    "test_size = len(series_scaled) - train_size\n",
    "train, test = series_scaled[0:train_size], series_scaled[train_size:len(series_scaled)]\n",
    "\n",
    "# Set parameters for TimeseriesGenerator\n",
    "time_steps = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create TimeseriesGenerator for training and testing\n",
    "train_generator = TimeseriesGenerator(train, train, length=time_steps, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(test, test, length=time_steps, batch_size=batch_size)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=50, validation_data=test_generator, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(test_generator)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Inverse transform y_test for comparison\n",
    "y_test_inverse = scaler.inverse_transform(test[time_steps:])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "print(\"Test MSE:\", mse(y_test_inverse, y_pred).numpy())\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test_inverse, color='blue', label='Actual')\n",
    "plt.plot(y_pred, color='red', label='Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Prints the values to a stream, or to sys.stdout by default.\n",
      "\n",
      "sep\n",
      "  string inserted between values, default a space.\n",
      "end\n",
      "  string appended after the last value, default a newline.\n",
      "file\n",
      "  a file-like object (stream); defaults to the current sys.stdout.\n",
      "flush\n",
      "  whether to forcibly flush the stream.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "print?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "# Assuming data is a pandas DataFrame with multiple input columns and one output column\n",
    "data = pd.read_csv('your_time_series_data.csv')\n",
    "\n",
    "# Split data into input features (X) and output (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Feature Scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set parameters for TimeseriesGenerator\n",
    "time_steps = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create TimeseriesGenerator for training and testing\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=time_steps, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(X_test, y_test, length=time_steps, batch_size=batch_size)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, X_train.shape[1])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=50, validation_data=test_generator, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(test_generator)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Inverse transform y_test for comparison\n",
    "y_test_inverse = scaler_y.inverse_transform(y_test[time_steps:])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "print(\"Test MSE:\", mse(y_test_inverse, y_pred).numpy())\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test_inverse, color='blue', label='Actual')\n",
    "plt.plot(y_pred, color='red', label='Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
